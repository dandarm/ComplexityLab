{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d4d4c5",
   "metadata": {},
   "source": [
    "# Misure di complessità per Lorenz, Hénon e mappa logistica\n",
    "Questo notebook genera tre serie temporali canoniche e applica le misure implementate in `measures.py`: autocorrelazione, ricostruzione di Takens, dimensione di correlazione, analisi di ricorrenza ed entropie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616bc2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from measures import (\n",
    "    autocorrelation,\n",
    "    integrated_autocorrelation_time,\n",
    "    time_delay_embedding,\n",
    "    correlation_dimension,\n",
    "    recurrence_matrix,\n",
    "    recurrence_quantification,\n",
    "    permutation_entropy,\n",
    "    sample_entropy,\n",
    "    largest_lyapunov_rosenstein,\n",
    ")\n",
    "from timeseries_generators import lorenz63, henon_map, logistic_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af81709d",
   "metadata": {},
   "source": [
    "## Generazione delle serie\n",
    "Simuliamo 8 000 passi scartando i primi 2 000 come transiente. Per il sistema di Lorenz analizziamo la coordinata `x`, per Hénon la componente `x` della coppia `(x, y)` e per la mappa logistica la serie stessa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3354f3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lorenz_traj = lorenz63(rho=28.0, dt=0.01, steps=8000, transient=2000)\n",
    "lorenz_series = lorenz_traj[:, 0]\n",
    "lorenz_dt = 0.01\n",
    "\n",
    "henon_traj = henon_map(a=1.4, b=0.3, steps=8000, transient=2000)\n",
    "henon_series = henon_traj[:, 0]\n",
    "henon_dt = 1.0\n",
    "\n",
    "logistic_series = logistic_map(r=3.9, x0=0.5, steps=8000, transient=2000)\n",
    "logistic_dt = 1.0\n",
    "\n",
    "series_dict = {\n",
    "    'Lorenz63': (lorenz_series, lorenz_dt),\n",
    "    'Henon': (henon_series, henon_dt),\n",
    "    'Logistic': (logistic_series, logistic_dt),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f426f3",
   "metadata": {},
   "source": [
    "## Funzioni ausiliarie\n",
    "Calcoliamo ritardi ottimali (primo valore in cui l'autocorrelazione scende sotto \\(1/e\\)), stimiamo la dimensione di correlazione con una regressione log-log e raccogliamo le misure richieste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49754bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_delay(acf):\n",
    "    target = np.exp(-1)\n",
    "    below = np.where(acf < target)[0]\n",
    "    if below.size == 0:\n",
    "        return 1\n",
    "    lag = int(below[0])\n",
    "    return max(1, lag)\n",
    "\n",
    "def compute_measures(series, dt):\n",
    "    acf = autocorrelation(series, max_lag=500)\n",
    "    tau = estimate_delay(acf)\n",
    "    emb_dim = 6\n",
    "    embedded = time_delay_embedding(series, emb_dim, tau)\n",
    "    radii = np.logspace(-3, 0, 24)\n",
    "    _, corr_integral, corr_dim = correlation_dimension(\n",
    "        series, emb_dim=emb_dim, delay=tau, radii=radii, max_points=4000, fit_range=(5, 18)\n",
    "    )\n",
    "    lyap = largest_lyapunov_rosenstein(series, dt, emb_dim=emb_dim, delay=tau)\n",
    "    tau_int = integrated_autocorrelation_time(series, max_lag=500)\n",
    "    subset = embedded[:2000]\n",
    "    R, eps = recurrence_matrix(subset, percentage=0.05)\n",
    "    rqa = recurrence_quantification(R)\n",
    "    perm_ent = permutation_entropy(series, order=5, delay=1, normalize=True)\n",
    "    samp_ent = sample_entropy(series, m=2, r=0.2)\n",
    "    return {\n",
    "        'tau_delay': tau,\n",
    "        'tau_int': tau_int,\n",
    "        'lyapunov': lyap,\n",
    "        'corr_dim': corr_dim,\n",
    "        'recurrence_eps': eps,\n",
    "        'perm_entropy': perm_ent,\n",
    "        'sample_entropy': samp_ent,\n",
    "        **rqa,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5544d4f2",
   "metadata": {},
   "source": [
    "## Risultati numerici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd39b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for name, (series, dt) in series_dict.items():\n",
    "    metrics = compute_measures(series, dt)\n",
    "    metrics['serie'] = name\n",
    "    rows.append(metrics)\n",
    "results_df = pd.DataFrame(rows).set_index('serie')\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44620ce0",
   "metadata": {},
   "source": [
    "## Visualizzazioni\n",
    "Mostriamo la funzione di autocorrelazione e il recurrence plot per ciascuna serie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df220901",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(series_dict), 2, figsize=(12, 4 * len(series_dict)))\n",
    "for idx, (name, (series, dt)) in enumerate(series_dict.items()):\n",
    "    acf = autocorrelation(series, max_lag=200)\n",
    "    axes[idx, 0].plot(acf)\n",
    "    axes[idx, 0].set_title(f'ACF - {name}')\n",
    "    axes[idx, 0].set_xlabel('Lag')\n",
    "    axes[idx, 0].set_ylabel('Autocorrelazione')\n",
    "    tau = estimate_delay(acf)\n",
    "    embedded = time_delay_embedding(series, 3, tau)[:500]\n",
    "    R, eps = recurrence_matrix(embedded, percentage=0.05)\n",
    "    axes[idx, 1].imshow(R, origin='lower', cmap='binary', interpolation='nearest')\n",
    "    axes[idx, 1].set_title(f'Recurrence plot - {name} (ε={eps:.3f})')\n",
    "    axes[idx, 1].set_xlabel('i')\n",
    "    axes[idx, 1].set_ylabel('j')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}